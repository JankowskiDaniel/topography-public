{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALCULATE_RAW_EPSILONS = False\n",
    "GENERATE_AVERAGE_NOISE = False\n",
    "GENERATE_FOURIER_NOISE = False\n",
    "GENERATE_AVERAGE_IMAGES = False\n",
    "GENERATE_FOURIER_IMAGES = True\n",
    "GENERATE_ALL_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_TYPE = \"ceramic\"\n",
    "NUM_RAW_IMAGES_FOR_NOISE_GENERATION = 100\n",
    "NUM_NOISE_IMAGES = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets make some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generation.datasets.generator_noise_average import (\n",
    "    generate_average_noise_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:51<00:00,  2.43it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_average_noise_dataset(\n",
    "    path=\"../data/noise/ceramic/\",\n",
    "    num_images=1000,\n",
    "    path_to_raw=\"../data/raw/ceramic/1channel/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_repo = os.path.dirname(os.getcwd())\n",
    "path_raw = os.path.join(path_repo, \"data/raw/\", NOISE_TYPE, \"/1channel\")\n",
    "path_average_noise = os.path.join(path_repo, \"data/noise/\", NOISE_TYPE)\n",
    "# path_fourier_noise = os.path.join(path_repo ,\"data/fourier_noise/\", NOISE_TYPE)\n",
    "# path_fourier_noise_freq = os.path.join(path_repo ,\"data/fourier_noise/\", NOISE_TYPE, \"freq\")\n",
    "# path_fourier_noise_ampl = os.path.join(path_repo ,\"data/fourier_noise/\", NOISE_TYPE, \"ampl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial images generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generation.datasets.generator import generate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # # params for blackbox\n",
    "    # \"width\": (30,150),\n",
    "    # \"height\": (30,100),\n",
    "    # \"x\": (0, 640),\n",
    "    # \"y\": (0, 480),\n",
    "    # # params for pizza\n",
    "    # \"nr_of_pizzas\": (10,20),\n",
    "    # \"center_point\": (320, 240),\n",
    "    # \"channels\": 1,\n",
    "    # \"strength\": (10,20),\n",
    "    # params for average\n",
    "    \"path_average_noise\": path_average_noise,\n",
    "    # # params for fourier\n",
    "    # \"path_fourier_noise_freq\": path_fourier_noise_freq,\n",
    "    # \"path_fourier_noise_ampl\": path_fourier_noise_ampl,\n",
    "    # \"domain\": \"ampl\",\n",
    "    # \"pass_value\": 4,\n",
    "    # \"noise_proportion\": 0.6,\n",
    "    # # params for bubble\n",
    "    # \"spray_particles\": 800,\n",
    "    # \"spray_diameter\": 8,\n",
    "    # \"fringes_color\": None,\n",
    "    # \"range_of_blobs\": (30,40)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier + Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [14:22<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "path_generated_fourier_freq = os.path.join(\n",
    "    path_repo, \"data/generated/average\", NOISE_TYPE, \"moved\"\n",
    ")\n",
    "generate_dataset(\n",
    "    noise_type=[\"average\"],\n",
    "    path=path_generated_fourier_freq,\n",
    "    name_prefix=f\"moved_{NOISE_TYPE}\",\n",
    "    n_copies=30,\n",
    "    epsilon_range=(0.0, 1.0),\n",
    "    epsilon_step=0.001,\n",
    "    # seed=23,\n",
    "    zipfile=False,\n",
    "    filename=f\"fourier_freq_{NOISE_TYPE}_10k.zip\",\n",
    "    parameters_filename=\"moved_parameters.csv\",\n",
    "    **params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "test_size=3000 should be either positive and smaller than the number of samples 1 or a float in the (0, 1) range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m GENERATE_FOURIER_IMAGES:\n\u001b[1;32m      2\u001b[0m     fourier_csv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_generated_fourier_freq, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfreq_parameters.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m     fourier_train, fourier_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfourier_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfourier_csv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepsilon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     fourier_train\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_generated_fourier_freq, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfourier_freq_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNOISE_TYPE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      6\u001b[0m     fourier_test\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_generated_fourier_freq, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfourier_freq_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNOISE_TYPE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Pulpit/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/Pulpit/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Pulpit/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2218\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2210\u001b[0m train_size_type \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(train_size)\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind\n\u001b[1;32m   2212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2213\u001b[0m     test_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (test_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;129;01mor\u001b[39;00m test_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2215\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m test_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2216\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (test_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m test_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2217\u001b[0m ):\n\u001b[0;32m-> 2218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_size=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m should be either positive and smaller\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m or a float in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(0, 1) range\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(test_size, n_samples)\n\u001b[1;32m   2222\u001b[0m     )\n\u001b[1;32m   2224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2225\u001b[0m     train_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (train_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;129;01mor\u001b[39;00m train_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m train_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (train_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m train_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2229\u001b[0m ):\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2231\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_size=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m should be either positive and smaller\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m or a float in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(0, 1) range\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_size, n_samples)\n\u001b[1;32m   2234\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: test_size=3000 should be either positive and smaller than the number of samples 1 or a float in the (0, 1) range"
     ]
    }
   ],
   "source": [
    "if GENERATE_FOURIER_IMAGES:\n",
    "    fourier_csv = pd.read_csv(\n",
    "        os.path.join(path_generated_fourier_freq, \"freq_parameters.csv\"),\n",
    "        index_col=False,\n",
    "    )\n",
    "    fourier_train, fourier_test = train_test_split(\n",
    "        fourier_csv,\n",
    "        test_size=3000,\n",
    "        random_state=12,\n",
    "        shuffle=True,\n",
    "        stratify=fourier_csv[\"epsilon\"],\n",
    "    )\n",
    "\n",
    "    fourier_train.to_csv(\n",
    "        os.path.join(\n",
    "            path_generated_fourier_freq, f\"fourier_freq_{NOISE_TYPE}_train.csv\"\n",
    "        )\n",
    "    )\n",
    "    fourier_test.to_csv(\n",
    "        os.path.join(path_generated_fourier_freq, f\"fourier_freq_{NOISE_TYPE}_test.csv\")\n",
    "    )\n",
    "\n",
    "    fourier_csv = pd.read_csv(\n",
    "        os.path.join(path_generated_fourier_ampl, \"ampl_parameters.csv\"),\n",
    "        index_col=False,\n",
    "    )\n",
    "    fourier_train, fourier_test = train_test_split(\n",
    "        fourier_csv,\n",
    "        test_size=3000,\n",
    "        random_state=12,\n",
    "        shuffle=True,\n",
    "        stratify=fourier_csv[\"epsilon\"],\n",
    "    )\n",
    "\n",
    "    fourier_train.to_csv(\n",
    "        os.path.join(\n",
    "            path_generated_fourier_ampl, f\"fourier_ampl_{NOISE_TYPE}_train.csv\"\n",
    "        )\n",
    "    )\n",
    "    fourier_test.to_csv(\n",
    "        os.path.join(path_generated_fourier_ampl, f\"fourier_ampl_{NOISE_TYPE}_test.csv\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 612/1000 [20:57<13:17,  2.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m GENERATE_ALL_IMAGES:\n\u001b[1;32m      2\u001b[0m     path_generated_all \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_repo ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/generated/all\u001b[39m\u001b[38;5;124m\"\u001b[39m, NOISE_TYPE)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbubble\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpizza\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maverage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblackbox\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_generated_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mNOISE_TYPE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_copies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mNOISE_TYPE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_10k.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Pulpit/topography-public/notebooks/../src/data_generation/datasets/generator.py:101\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[0;34m(noise_type, path, n_copies, name_prefix, epsilon_range, epsilon_step, size, brightness, center_shift, zipfile, filename, save_parameters, parameters_filename, seed, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m img_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(img_index)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zipfile:\n\u001b[0;32m--> 101\u001b[0m     \u001b[43msave2zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     save2directory(img, img_filename, path)\n",
      "File \u001b[0;32m~/Pulpit/topography-public/notebooks/../src/data_generation/datasets/generate_utils.py:30\u001b[0m, in \u001b[0;36msave2zip\u001b[0;34m(img, img_filename, filename, path)\u001b[0m\n\u001b[1;32m     27\u001b[0m     zip_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, filename)\n\u001b[1;32m     29\u001b[0m _, encoded_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;28mzip\u001b[39m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mzip\u001b[39m\u001b[38;5;241m.\u001b[39mwritestr(img_filename, encoded_image\u001b[38;5;241m.\u001b[39mtobytes())\n",
      "File \u001b[0;32m/usr/lib/python3.10/zipfile.py:1289\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;66;03m# See if file is a zip file\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m         \u001b[38;5;66;03m# seek to start of directory and overwrite\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_dir)\n",
      "File \u001b[0;32m/usr/lib/python3.10/zipfile.py:1378\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     filename \u001b[38;5;241m=\u001b[39m filename\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp437\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;66;03m# Create ZipInfo instance to store file information\u001b[39;00m\n\u001b[0;32m-> 1378\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mZipInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m x\u001b[38;5;241m.\u001b[39mextra \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(centdir[_CD_EXTRA_FIELD_LENGTH])\n\u001b[1;32m   1380\u001b[0m x\u001b[38;5;241m.\u001b[39mcomment \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(centdir[_CD_COMMENT_LENGTH])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if GENERATE_ALL_IMAGES:\n",
    "    path_generated_all = os.path.join(path_repo, \"data/generated/all\", NOISE_TYPE)\n",
    "    generate_dataset(\n",
    "        noise_type=[\"bubble\", \"pizza\", \"average\", \"blackbox\"],\n",
    "        path=path_generated_all,\n",
    "        name_prefix=f\"all_{NOISE_TYPE}\",\n",
    "        n_copies=10,\n",
    "        epsilon_range=(0.0, 1.0),\n",
    "        epsilon_step=0.001,\n",
    "        seed=23,\n",
    "        zipfile=True,\n",
    "        filename=f\"all_{NOISE_TYPE}_10k.zip\",\n",
    "        **params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_ALL_IMAGES:\n",
    "    all_csv = pd.read_csv(\n",
    "        os.path.join(path_generated_all, \"parameters.csv\"), index_col=False\n",
    "    )\n",
    "    all_train, all_test = train_test_split(\n",
    "        all_csv,\n",
    "        test_size=3000,\n",
    "        random_state=12,\n",
    "        shuffle=True,\n",
    "        stratify=all_csv[\"epsilon\"],\n",
    "    )\n",
    "\n",
    "    all_train.to_csv(os.path.join(path_generated_all, f\"all_{NOISE_TYPE}_train.csv\"))\n",
    "    all_test.to_csv(os.path.join(path_generated_all, f\"all_{NOISE_TYPE}_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:22<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# if GENERATE_AVERAGE_IMAGES:\n",
    "path_generated_average = os.path.join(\n",
    "    path_repo, \"data/generated/perlin_ceramic_moved_test/pure_average/\"\n",
    ")\n",
    "generate_dataset(\n",
    "    noise_type=[\"average\"],\n",
    "    path=path_generated_average,\n",
    "    name_prefix=f\"average_{NOISE_TYPE}\",\n",
    "    n_copies=15,\n",
    "    epsilon_range=(0.0, 1.0),\n",
    "    epsilon_step=0.001,\n",
    "    # seed=23,\n",
    "    seed=32,\n",
    "    zipfile=False,\n",
    "    # filename=f\"average_{NOISE_TYPE}_10k.zip\",\n",
    "    **params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_AVERAGE_IMAGES:\n",
    "    average_csv = pd.read_csv(\n",
    "        os.path.join(path_generated_average, \"parameters.csv\"), index_col=False\n",
    "    )\n",
    "    average_train, average_test = train_test_split(\n",
    "        average_csv,\n",
    "        test_size=3000,\n",
    "        random_state=12,\n",
    "        shuffle=True,\n",
    "        stratify=average_csv[\"epsilon\"],\n",
    "    )\n",
    "\n",
    "    average_train.to_csv(\n",
    "        os.path.join(path_generated_average, f\"average_{NOISE_TYPE}_train.csv\")\n",
    "    )\n",
    "    average_test.to_csv(\n",
    "        os.path.join(path_generated_average, f\"average_{NOISE_TYPE}_test.csv\")\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
