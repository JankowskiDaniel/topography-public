{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_AVERAGE_NOISE = False\n",
    "GENERATE_FOURIER_NOISE = False\n",
    "GENERATE_AVERAGE_IMAGES = False\n",
    "GENERATE_FOURIER_IMAGES = True\n",
    "GENERATE_ALL_IMAGES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_TYPE = \"steel\"\n",
    "NUM_RAW_IMAGES_FOR_NOISE_GENERATION = 100\n",
    "NUM_NOISE_IMAGES = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets make some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generation.datasets.generator_noise_average import generate_average_noise_dataset\n",
    "from src.data_generation.datasets.generator_noise_fourier import generate_fourier_noise_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_repo = os.path.dirname(os.getcwd())\n",
    "path_raw = os.path.join(path_repo ,\"data/raw/steel/1channel\")\n",
    "path_average_noise = os.path.join(path_repo ,\"data/average_noise/\", NOISE_TYPE)\n",
    "path_fourier_noise = os.path.join(path_repo ,\"data/fourier_noise/\", NOISE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:19<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_average_noise_dataset(\n",
    "        path_to_raw=path_raw,\n",
    "        path=path_average_noise,\n",
    "        num_images=NUM_NOISE_IMAGES,\n",
    "        num_used_raw_images=NUM_RAW_IMAGES_FOR_NOISE_GENERATION,\n",
    "        seed=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available raw images:  100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:18<00:00, 26.79it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_fourier_noise_dataset(\n",
    "        path=path_fourier_noise,\n",
    "        num_images=NUM_NOISE_IMAGES,\n",
    "        path_to_raw=path_raw,\n",
    "        seed=25,\n",
    "        pass_value=4 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial images generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generation.datasets.generator import generate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # params for blackbox\n",
    "    \"width\": (30,150),\n",
    "    \"height\": (30,100),\n",
    "    \"x\": (0, 640),\n",
    "    \"y\": (0, 480),\n",
    "    # params for pizza\n",
    "    \"nr_of_pizzas\": (10,20),\n",
    "    \"center_point\": (320, 240),\n",
    "    \"channels\": 1,\n",
    "    \"strength\": (10,20),\n",
    "    # params for average\n",
    "    \"path_average_noise\": path_average_noise,\n",
    "    \"path_fourier_noise\": path_fourier_noise,\n",
    "    # params for bubble\n",
    "    \"spray_particles\": 800,\n",
    "    \"spray_diameter\": 8,\n",
    "    \"fringes_color\": None,\n",
    "    \"range_of_blobs\": (30,40)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier + Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [07:45<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "path_generated_fourier = os.path.join(path_repo ,\"data/generated/fourier/single\")\n",
    "generate_dataset(\n",
    "        noise_type=[\"fourier\"],\n",
    "        path=path_generated_fourier,\n",
    "        name_prefix=f\"fourier_single_{NOISE_TYPE}\",\n",
    "        n_copies=10,\n",
    "        epsilon_range=(0.0, 1.0),\n",
    "        epsilon_step=0.001,\n",
    "        seed=25,\n",
    "        zipfile=False,\n",
    "        **params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_FOURIER_IMAGES:\n",
    "    fourier_csv = pd.read_csv(os.path.join(path_generated_fourier, \"parameters.csv\"), index_col=False)\n",
    "    fourier_train, fourier_test = train_test_split(fourier_csv, test_size=3000, random_state=12, shuffle=True, stratify=fourier_csv['epsilon'])\n",
    "\n",
    "    fourier_train.to_csv(os.path.join(path_generated_fourier, f\"fourier_{NOISE_TYPE}_train.csv\"))\n",
    "    fourier_test.to_csv(os.path.join(path_generated_fourier, f\"fourier_{NOISE_TYPE}_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_ALL_IMAGES:\n",
    "    path_generated_all = os.path.join(path_repo ,\"data/generated/all\", NOISE_TYPE)\n",
    "    generate_dataset(\n",
    "        noise_type=[\"bubble\", \"pizza\", \"average\", \"blackbox\"],\n",
    "        path=path_generated_all,\n",
    "        name_prefix=f\"all_{NOISE_TYPE}\",\n",
    "        n_copies=10,\n",
    "        epsilon_range=(0.0, 1.0),\n",
    "        epsilon_step=0.001,\n",
    "        seed=23,\n",
    "        zipfile=True,\n",
    "        filename=f\"all_{NOISE_TYPE}_10k.zip\",\n",
    "        **params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_generated_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_csv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mpath_generated_all\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m all_train, all_test \u001b[38;5;241m=\u001b[39m train_test_split(all_csv, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, stratify\u001b[38;5;241m=\u001b[39mall_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m all_train\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_generated_all, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNOISE_TYPE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_generated_all' is not defined"
     ]
    }
   ],
   "source": [
    "if GENERATE_ALL_IMAGES:\n",
    "    all_csv = pd.read_csv(os.path.join(path_generated_all, \"parameters.csv\"), index_col=False)\n",
    "    all_train, all_test = train_test_split(all_csv, test_size=3000, random_state=12, shuffle=True, stratify=all_csv['epsilon'])\n",
    "\n",
    "    all_train.to_csv(os.path.join(path_generated_all, f\"all_{NOISE_TYPE}_train.csv\"))\n",
    "    all_test.to_csv(os.path.join(path_generated_all, f\"all_{NOISE_TYPE}_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [08:43<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_AVERAGE_IMAGES:\n",
    "    path_generated_average = os.path.join(path_repo ,\"data/generated/average\", NOISE_TYPE)\n",
    "    generate_dataset(\n",
    "        noise_type=[\"average\"],\n",
    "        path=path_generated_average,\n",
    "        name_prefix=f\"average_{NOISE_TYPE}\",\n",
    "        n_copies=10,\n",
    "        epsilon_range=(0.0, 1.0),\n",
    "        epsilon_step=0.001,\n",
    "        seed=23,\n",
    "        zipfile=True,\n",
    "        filename=f\"average_{NOISE_TYPE}_10k.zip\",\n",
    "        **params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_AVERAGE_IMAGES:\n",
    "    average_csv = pd.read_csv(os.path.join(path_generated_average, \"parameters.csv\"), index_col=False)\n",
    "    average_train, average_test = train_test_split(average_csv, test_size=3000, random_state=12, shuffle=True, stratify=average_csv['epsilon'])\n",
    "\n",
    "    average_train.to_csv(os.path.join(path_generated_average, f\"average_{NOISE_TYPE}_train.csv\"))\n",
    "    average_test.to_csv(os.path.join(path_generated_average, f\"average_{NOISE_TYPE}_test.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
