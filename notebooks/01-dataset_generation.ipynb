{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob \n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALCULATE_RAW_EPSILONS = True\n",
    "GENERATE_AVERAGE_NOISE = True\n",
    "GENERATE_FOURIER_NOISE = True\n",
    "GENERATE_AVERAGE_IMAGES = True\n",
    "GENERATE_FOURIER_IMAGES = True\n",
    "GENERATE_ALL_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_TYPE = \"steel\"\n",
    "NUM_RAW_IMAGES_FOR_NOISE_GENERATION = 100\n",
    "NUM_NOISE_IMAGES = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets make some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generation.datasets.generator_noise_average import generate_average_noise_dataset\n",
    "from src.data_generation.datasets.generator_noise_fourier import generate_fourier_noise_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_repo = os.path.dirname(os.getcwd())\n",
    "path_raw = os.path.join(path_repo ,\"data/raw/\", NOISE_TYPE, \"/1channel\")\n",
    "path_average_noise = os.path.join(path_repo ,\"data/average_noise/\", NOISE_TYPE)\n",
    "path_fourier_noise = os.path.join(path_repo ,\"data/fourier_noise/\", NOISE_TYPE)\n",
    "path_fourier_noise_freq = os.path.join(path_repo ,\"data/fourier_noise/\", NOISE_TYPE, \"freq\")\n",
    "path_fourier_noise_ampl = os.path.join(path_repo ,\"data/fourier_noise/\", NOISE_TYPE, \"ampl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m method \u001b[38;5;241m=\u001b[39m AnalyticalMathodOld()\n\u001b[0;32m      8\u001b[0m eps_est \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39marray(paths), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43meps_est\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_epsilon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     11\u001b[0m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mround\u001b[39m(x, \u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\janko\\OneDrive\\Pulpit\\Artificial intelligence\\Magisterka\\topography-public\\venv_torch\\Lib\\site-packages\\pandas\\core\\series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4791\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janko\\OneDrive\\Pulpit\\Artificial intelligence\\Magisterka\\topography-public\\venv_torch\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janko\\OneDrive\\Pulpit\\Artificial intelligence\\Magisterka\\topography-public\\venv_torch\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\janko\\OneDrive\\Pulpit\\Artificial intelligence\\Magisterka\\topography-public\\venv_torch\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janko\\OneDrive\\Pulpit\\Artificial intelligence\\Magisterka\\topography-public\\venv_torch\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m method \u001b[38;5;241m=\u001b[39m AnalyticalMathodOld()\n\u001b[0;32m      8\u001b[0m eps_est \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39marray(paths), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: method\u001b[38;5;241m.\u001b[39mcalculate_epsilon(\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     10\u001b[0m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     11\u001b[0m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m eps_est[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mround\u001b[39m(x, \u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if CALCULATE_RAW_EPSILONS:\n",
    "    import sys\n",
    "    sys.path.append('../src')\n",
    "    from methods.analytic.exact import AnalyticalMathodOld\n",
    "\n",
    "    paths = glob.glob(os.path.join(path_raw, \"*.png\"))\n",
    "    method = AnalyticalMathodOld()\n",
    "    eps_est = pd.DataFrame(np.array(paths), columns=['path'])\n",
    "    eps_est[\"epsilon\"] = eps_est[\"path\"].apply(lambda x: method.calculate_epsilon(cv2.imread(x, cv2.IMREAD_GRAYSCALE)))\n",
    "    eps_est[\"epsilon\"] = eps_est[\"epsilon\"].apply(lambda x: x[0])\n",
    "    eps_est[\"epsilon\"] = eps_est[\"epsilon\"].apply(lambda x: round(x, 3))\n",
    "    eps_est.to_csv(os.path.join(path_fourier_noise, \"raw_epsilons.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:03<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_AVERAGE_NOISE:\n",
    "    generate_average_noise_dataset(\n",
    "        path_to_raw=path_raw,\n",
    "        path=path_average_noise,\n",
    "        num_images=NUM_NOISE_IMAGES,\n",
    "        num_used_raw_images=NUM_RAW_IMAGES_FOR_NOISE_GENERATION,\n",
    "        seed=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/home/shapke/Pulpit/topography-public/data/raw...</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/shapke/Pulpit/topography-public/data/raw...</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/home/shapke/Pulpit/topography-public/data/raw...</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/home/shapke/Pulpit/topography-public/data/raw...</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/home/shapke/Pulpit/topography-public/data/raw...</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               path  epsilon\n",
       "0           0  /home/shapke/Pulpit/topography-public/data/raw...    0.786\n",
       "1           1  /home/shapke/Pulpit/topography-public/data/raw...    0.780\n",
       "2           2  /home/shapke/Pulpit/topography-public/data/raw...    0.912\n",
       "3           3  /home/shapke/Pulpit/topography-public/data/raw...    0.722\n",
       "4           4  /home/shapke/Pulpit/topography-public/data/raw...    0.864"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_fourier_noise + \"/raw_epsilons.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:04<00:00, 108.16it/s]\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_FOURIER_NOISE:\n",
    "    # generate_fourier_noise_dataset(\n",
    "    #     path=path_fourier_noise_ampl,\n",
    "    #     raw_epsilons_path=path_fourier_noise,\n",
    "    #     num_images=NUM_NOISE_IMAGES,\n",
    "    #     seed=23,\n",
    "    #     pass_value=4,\n",
    "    #     domain=\"amplitude\"\n",
    "    # )\n",
    "    generate_fourier_noise_dataset(\n",
    "        path=path_fourier_noise_freq,\n",
    "        raw_epsilons_path=path_fourier_noise,\n",
    "        num_images=NUM_NOISE_IMAGES,\n",
    "        seed=23,\n",
    "        pass_value=4,\n",
    "        domain=\"freq\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial images generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generation.datasets.generator import generate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # params for blackbox\n",
    "    \"width\": (30,150),\n",
    "    \"height\": (30,100),\n",
    "    \"x\": (0, 640),\n",
    "    \"y\": (0, 480),\n",
    "    # params for pizza\n",
    "    \"nr_of_pizzas\": (10,20),\n",
    "    \"center_point\": (320, 240),\n",
    "    \"channels\": 1,\n",
    "    \"strength\": (10,20),\n",
    "    # params for average\n",
    "    \"path_average_noise\": path_average_noise,\n",
    "    # params for fourier\n",
    "    \"path_fourier_noise_freq\": path_fourier_noise_freq,\n",
    "    \"path_fourier_noise_ampl\": path_fourier_noise_ampl,\n",
    "    \"domain\": \"ampl\",\n",
    "    \"pass_value\": 4,\n",
    "    # params for bubble\n",
    "    \"spray_particles\": 800,\n",
    "    \"spray_diameter\": 8,\n",
    "    \"fringes_color\": None,\n",
    "    \"range_of_blobs\": (30,40)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier + Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [07:41<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_FOURIER_IMAGES:\n",
    "    path_generated_fourier_freq = os.path.join(path_repo ,\"data/generated/fourier\", NOISE_TYPE, \"freq\")\n",
    "    params[\"domain\"] = \"freq\"\n",
    "    generate_dataset(\n",
    "        noise_type=[\"fourier\"],\n",
    "        path=path_generated_fourier_freq,\n",
    "        name_prefix=f\"fourier_{NOISE_TYPE}_freq_single\",\n",
    "        n_copies=10,\n",
    "        epsilon_range=(0.0, 1.0),\n",
    "        epsilon_step=0.001,\n",
    "        seed=42,\n",
    "        zipfile=True,\n",
    "        filename=f\"fourier_freq_{NOISE_TYPE}_10k_single.zip\",\n",
    "        parameters_filename=\"freq_single_parameters.csv\",\n",
    "        **params\n",
    "    )\n",
    "    # path_generated_fourier_ampl = os.path.join(path_repo ,\"data/generated/fourier\", NOISE_TYPE, \"ampl\")\n",
    "    # params[\"domain\"] = \"ampl\"\n",
    "    # generate_dataset(\n",
    "    #     noise_type=[\"fourier\", \"average\"],\n",
    "    #     path=path_generated_fourier_ampl,\n",
    "    #     name_prefix=f\"fourier_{NOISE_TYPE}_ampl\",\n",
    "    #     n_copies=10,\n",
    "    #     epsilon_range=(0.0, 1.0),\n",
    "    #     epsilon_step=0.001,\n",
    "    #     seed=23,\n",
    "    #     zipfile=True,\n",
    "    #     filename=f\"fourier_ampl_{NOISE_TYPE}_10k.zip\",\n",
    "    #     parameters_filename=\"ampl_parameters.csv\",\n",
    "    #     **params\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_FOURIER_IMAGES:\n",
    "    fourier_csv = pd.read_csv(os.path.join(path_generated_fourier_freq, \"freq_parameters.csv\"), index_col=False)\n",
    "    fourier_train, fourier_test = train_test_split(fourier_csv, test_size=3000, random_state=12, shuffle=True, stratify=fourier_csv['epsilon'])\n",
    "\n",
    "    fourier_train.to_csv(os.path.join(path_generated_fourier_freq, f\"fourier_freq_{NOISE_TYPE}_train.csv\"))\n",
    "    fourier_test.to_csv(os.path.join(path_generated_fourier_freq, f\"fourier_freq_{NOISE_TYPE}_test.csv\"))\n",
    "\n",
    "    fourier_csv = pd.read_csv(os.path.join(path_generated_fourier_ampl, \"ampl_parameters.csv\"), index_col=False)\n",
    "    fourier_train, fourier_test = train_test_split(fourier_csv, test_size=3000, random_state=12, shuffle=True, stratify=fourier_csv['epsilon'])\n",
    "\n",
    "    fourier_train.to_csv(os.path.join(path_generated_fourier_ampl, f\"fourier_ampl_{NOISE_TYPE}_train.csv\"))\n",
    "    fourier_test.to_csv(os.path.join(path_generated_fourier_ampl, f\"fourier_ampl_{NOISE_TYPE}_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 612/1000 [20:57<13:17,  2.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m GENERATE_ALL_IMAGES:\n\u001b[1;32m      2\u001b[0m     path_generated_all \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_repo ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/generated/all\u001b[39m\u001b[38;5;124m\"\u001b[39m, NOISE_TYPE)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbubble\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpizza\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maverage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblackbox\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_generated_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mNOISE_TYPE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_copies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mNOISE_TYPE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_10k.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Pulpit/topography-public/notebooks/../src/data_generation/datasets/generator.py:101\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[0;34m(noise_type, path, n_copies, name_prefix, epsilon_range, epsilon_step, size, brightness, center_shift, zipfile, filename, save_parameters, parameters_filename, seed, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m img_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(img_index)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zipfile:\n\u001b[0;32m--> 101\u001b[0m     \u001b[43msave2zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     save2directory(img, img_filename, path)\n",
      "File \u001b[0;32m~/Pulpit/topography-public/notebooks/../src/data_generation/datasets/generate_utils.py:30\u001b[0m, in \u001b[0;36msave2zip\u001b[0;34m(img, img_filename, filename, path)\u001b[0m\n\u001b[1;32m     27\u001b[0m     zip_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, filename)\n\u001b[1;32m     29\u001b[0m _, encoded_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;28mzip\u001b[39m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mzip\u001b[39m\u001b[38;5;241m.\u001b[39mwritestr(img_filename, encoded_image\u001b[38;5;241m.\u001b[39mtobytes())\n",
      "File \u001b[0;32m/usr/lib/python3.10/zipfile.py:1289\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;66;03m# See if file is a zip file\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m         \u001b[38;5;66;03m# seek to start of directory and overwrite\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_dir)\n",
      "File \u001b[0;32m/usr/lib/python3.10/zipfile.py:1378\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     filename \u001b[38;5;241m=\u001b[39m filename\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp437\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;66;03m# Create ZipInfo instance to store file information\u001b[39;00m\n\u001b[0;32m-> 1378\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mZipInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m x\u001b[38;5;241m.\u001b[39mextra \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(centdir[_CD_EXTRA_FIELD_LENGTH])\n\u001b[1;32m   1380\u001b[0m x\u001b[38;5;241m.\u001b[39mcomment \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(centdir[_CD_COMMENT_LENGTH])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if GENERATE_ALL_IMAGES:\n",
    "    path_generated_all = os.path.join(path_repo ,\"data/generated/all\", NOISE_TYPE)\n",
    "    generate_dataset(\n",
    "        noise_type=[\"bubble\", \"pizza\", \"average\", \"blackbox\"],\n",
    "        path=path_generated_all,\n",
    "        name_prefix=f\"all_{NOISE_TYPE}\",\n",
    "        n_copies=10,\n",
    "        epsilon_range=(0.0, 1.0),\n",
    "        epsilon_step=0.001,\n",
    "        seed=23,\n",
    "        zipfile=True,\n",
    "        filename=f\"all_{NOISE_TYPE}_10k.zip\",\n",
    "        **params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_ALL_IMAGES:\n",
    "    all_csv = pd.read_csv(os.path.join(path_generated_all, \"parameters.csv\"), index_col=False)\n",
    "    all_train, all_test = train_test_split(all_csv, test_size=3000, random_state=12, shuffle=True, stratify=all_csv['epsilon'])\n",
    "\n",
    "    all_train.to_csv(os.path.join(path_generated_all, f\"all_{NOISE_TYPE}_train.csv\"))\n",
    "    all_test.to_csv(os.path.join(path_generated_all, f\"all_{NOISE_TYPE}_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_AVERAGE_IMAGES:\n",
    "    path_generated_average = os.path.join(path_repo ,\"data/generated/average\", NOISE_TYPE)\n",
    "    generate_dataset(\n",
    "        noise_type=[\"average\"],\n",
    "        path=path_generated_average,\n",
    "        name_prefix=f\"average_{NOISE_TYPE}\",\n",
    "        n_copies=10,\n",
    "        epsilon_range=(0.0, 1.0),\n",
    "        epsilon_step=0.001,\n",
    "        seed=23,\n",
    "        zipfile=True,\n",
    "        filename=f\"average_{NOISE_TYPE}_10k.zip\",\n",
    "        **params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_AVERAGE_IMAGES:\n",
    "    average_csv = pd.read_csv(os.path.join(path_generated_average, \"parameters.csv\"), index_col=False)\n",
    "    average_train, average_test = train_test_split(average_csv, test_size=3000, random_state=12, shuffle=True, stratify=average_csv['epsilon'])\n",
    "\n",
    "    average_train.to_csv(os.path.join(path_generated_average, f\"average_{NOISE_TYPE}_train.csv\"))\n",
    "    average_test.to_csv(os.path.join(path_generated_average, f\"average_{NOISE_TYPE}_test.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
